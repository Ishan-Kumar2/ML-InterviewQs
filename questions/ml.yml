---
# Put your questions here:

questions:
  title: Gradient Descent dependence on order of training data
  type: mcq
  text: Which of the following optimization algorithms does not depend on the order of training data?
  opt:
    - Batch Gradient Descent
    - Mini-batch Gradient Descent
    - Stochastic Gradient Descent
  ans: 
    - Batch Gradient Descent
  q_img: NULL
  sol:
    A full batch gradient descent goes through the entire dataset in every iteration. Also, the operations we perform are commutative and hence the order of the training examples does not matter.
  sol_img: NULL
  tags: 
    - gradient-descent
  diff: easy
  ref: NULL

  title: Need for feature scaling
  type: mcq
  text: Which of these methods does not require you to do feature scaling on the input data?
  opt:
    - Principal Component Analysis (PCA)
    - Support Vector Machines (SVM)
    - Decision Trees
    - K Means Clustering
  ans: Decision Trees
    - 
  q_img: NULL
  sol:
    Decision trees don't require feature scaling as they use a rule-based approach instead of calculating distances.
  sol_img: NULL
  tags: 
    - svm
    - trees
  diff: easy
  ref: NULL